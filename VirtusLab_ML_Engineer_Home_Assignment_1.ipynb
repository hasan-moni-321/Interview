{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 ML Engineer Home Assignment\n",
    "\n",
    "This is a Jupyter notebook containing exercises from 3  fields: \n",
    "1. Algorithms,\n",
    "2. Python,\n",
    "3. Spark.\n",
    "\n",
    "We think that it is possible to complete it within a couple hours and we are expecting that you will send back the results within a week (7 days).  \n",
    "Your submission can be in the form of this notebook with your code and necessary remarks added to it but we are fine with other forms, as well as partial solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python requirements:\n",
    "\n",
    "You can use the below library versions for running this notebook.\n",
    "\n",
    "If you are using Conda to manage you Python environments you can use the command like below:\n",
    "```\n",
    "conda create --name vl-home-assignment --file requirements.txt\n",
    "```\n",
    "\n",
    "Requirements:\n",
    "```\n",
    "pyspark=2.3.0\n",
    "python=3.6.10\n",
    "jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 1: Algorithms\n",
    "\n",
    "You are given two singly-linked lists (precisely: the references to their heads).\n",
    "Implement an optimal (both in terms of memory and time) function that returns the intersection node.  \n",
    "\n",
    "We define intersection based on reference, not value. \n",
    "That is, if the k-th element of the first list is exactly the same node reference as the j-th element of the second list then the lists intersect. \n",
    "We expect that your solution will provide your own implementation of the singly-linked lists. \n",
    "Please provide a couple of examples testing your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for you solution\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "\n",
    "class Create_Node:\n",
    "    def __init__(self, dataval=None):\n",
    "        self.dataval = dataval\n",
    "        self.nextval = None\n",
    "        \n",
    "    \n",
    "class Create_LinkedList:\n",
    "    def __init__(self):\n",
    "        self.headval = None\n",
    "        \n",
    "    \n",
    "    def reference_of_node(self, list_name):\n",
    "        node_value = self.headval\n",
    "        while node_value is not None:\n",
    "            #print (printval.dataval)\n",
    "            rv = random.randint(5,50)   # You can change upper and lower value\n",
    "\n",
    "            if list_name == list1:\n",
    "                list1.append(rv)\n",
    "            else:\n",
    "                list2.append(rv)\n",
    "            node_value = node_value.nextval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First linked list\n",
    "list = Create_LinkedList()\n",
    "list.headval = Create_Node(\"fish\")\n",
    "e2 = Create_Node(\"vegetable\")\n",
    "e3 = Create_Node(\"chicken\")\n",
    "e4 = Create_Node(\"beef\")\n",
    "e5 = Create_Node(\"mutton\") \n",
    "\n",
    "# Link first Node to second node\n",
    "list.headval.nextval = e2\n",
    "\n",
    "# Link second Node to third node\n",
    "e2.nextval = e3\n",
    "e3.nextval = e4\n",
    "e4.nextval = e5\n",
    "\n",
    "\n",
    "list.reference_of_node(list1)\n",
    "\n",
    "\n",
    "# Second linked list\n",
    "list = Create_LinkedList()\n",
    "list.headval = Create_Node(\"computer\")\n",
    "e2 = Create_Node(\"mouse\")\n",
    "e3 = Create_Node(\"heartdisk\")\n",
    "e4 = Create_Node(\"laptop\")\n",
    "e5 = Create_Node(\"monitor\") \n",
    "\n",
    "\n",
    "# Link first Node to second node\n",
    "list.headval.nextval = e2\n",
    "\n",
    "# Link second Node to third node\n",
    "e2.nextval = e3\n",
    "e3.nextval = e4\n",
    "e4.nextval = e5\n",
    "\n",
    "list.reference_of_node(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [d for d in list1 if d in list2]\n",
    "\n",
    "print(f\"Generated list1 is {list1} and \\ngenerated list2 is {list2}\")\n",
    "\n",
    "if not c:\n",
    "    print(\"There is not intersection between two list\")\n",
    "if c:\n",
    "    print('Yes! There is intersection between two list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 2: Python\n",
    "\n",
    "Given two files `file.json` and `file.csv` containing the same mapping write a small library with loaders for these file formats. \n",
    "A loader `l` should have two public members `l.keys` and `l.data`.\n",
    "There should be a basic filtering functionality built around `keys` attribute as in the example below.\n",
    "\n",
    "Use Python Standard Library for parsing json and csv files.\n",
    "\n",
    "### Sample files\n",
    "`file.json`:\n",
    "```\n",
    "{\n",
    "  \"alfa\": 1,\n",
    "  \"beta\": 2\n",
    "}\n",
    "```\n",
    "`file.csv`:\n",
    "```\n",
    "alfa,1\n",
    "beta,2\n",
    "```\n",
    "\n",
    "### Sample usage\n",
    "```\n",
    "from file_loaders import JsonLoader, CsvLoader\n",
    "loaders: Tuple[Loader] = (\n",
    "    JsonLoader('file.json'),\n",
    "    CsvLoader('file.csv')\n",
    ")\n",
    "for l in loaders:\n",
    "    print(f\"======== {type(l).__name__} =======\")\n",
    "    print(f\"data: {l.data}\") # => {'alfa': 1, 'beta': 2}\n",
    "    print(f\"keys: {l.keys}\") # => ('alfa', 'beta')\n",
    "    l.keys = ('alfa')\n",
    "    print(f\"data: {l.data}\") # => {'alfa': 1}\n",
    "    print(f\"keys: {l.keys}\") # => alfa\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for your solution\n",
    "\n",
    "# Creating json file\n",
    "import json\n",
    "import pandas as pd\n",
    "data = {\n",
    "    \"alfa\": [],\n",
    "    \"beta\": []\n",
    "}\n",
    "data['alfa'].append(1)\n",
    "data['beta'].append(2)\n",
    "\n",
    "with open('data.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)\n",
    "json_file = pd.read_json(\"data.json\")  # reading json file using pandas, I could also read using json  \n",
    "json_file = tuple(json_file)  # json to tuple\n",
    "json_file    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv file\n",
    "data = {\n",
    "    \"alfa\":[1],\n",
    "    \"beta\":[2]\n",
    "}\n",
    "\n",
    "df_file = pd.DataFrame(data)\n",
    "df_file.to_csv(\"data.csv\", index=None)\n",
    "file_csv = pd.read_csv(\"data.csv\")\n",
    "file_csv = file_csv.to_dict(orient='list') # DataFrame to dictionary \n",
    "file_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    \"data\": file_csv,\n",
    "    \"keys\": json_file\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders['keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders['keys'] = loaders['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders['keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 3: Spark\n",
    "\n",
    "Below are two Spark dataframes representing 1) people and 2) hobbies.\n",
    "You are given two tasks.\n",
    "1. Show how many hobbies each person has.\n",
    "2. Show all hobbies that no one has.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# global spark session\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName('MLEngineerSpark')\n",
    "         .master('local[2]')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df = spark.createDataFrame(\n",
    "            data=[\n",
    "                (1, \"Mary\"),\n",
    "                (2, \"John\"),\n",
    "                (4, \"Tom\"),\n",
    "            ], schema=(\"id\",\"name\"))\n",
    "\n",
    "hobbies_df = spark.createDataFrame(\n",
    "            data=[\n",
    "                (1, \"Python\"),\n",
    "                (1, \"Spark\"),\n",
    "                (1, \"Reading\"),\n",
    "                (2, \"Sleeping\"),\n",
    "                (3, \"Soccer\"),\n",
    "            ], schema=(\"id\",\"hobby\"))\n",
    "\n",
    "persons_df.show(truncate=False)\n",
    "hobbies_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Show how many hobbies each person has.\n",
    "# Space for you solution\n",
    "\n",
    "# tempview for using sql\n",
    "persons_df.createOrReplaceTempView(\"people\")\n",
    "hobbies_df.createOrReplaceTempView(\"hobby\")\n",
    "\n",
    "spark.sql(\"SELECT p.name, COUNT(*) as hobby_number from people p inner join hobby h on p.id=h.id group by name having count(*)\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Show all hobbies that no one has.\n",
    "# Space for you solution\n",
    "\n",
    "# using alias\n",
    "from pyspark.sql import functions as F\n",
    "ta = persons_df.alias('ta')\n",
    "tb = hobbies_df.alias('tb')\n",
    "\n",
    "left_join = tb.join(ta, tb.id == ta.id, how='left').filter(F.col('ta.name').isNull())\n",
    "\n",
    "left_join.createOrReplaceTempView(\"new_sql\")\n",
    "spark.sql(\"select hobby from new_sql\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another technique of the second problem\n",
    "spark.sql(\"select id, hobby from hobby where id not in (select id from people)\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
